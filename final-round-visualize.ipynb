{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *0. Librabry & Defined functions* ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import clip\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_VIDEO = '/run/media/zephy_manjaro/Crucial X6/AIC2022/data/video/'\n",
    "PATH_KEYFRAMES = '/run/media/zephy_manjaro/Crucial X6/AIC2022/data/keyframes/'\n",
    "PATH_METADATA = 'data/metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_df(bonus_df, main_df):\n",
    "    \n",
    "    remain_len_for_main_df = len(main_df) - len(bonus_df)\n",
    "    remain_df = main_df.head(remain_len_for_main_df)\n",
    "\n",
    "    final_df = pd.concat([bonus_df, remain_df], ignore_index = True)\n",
    "    \n",
    "    final_df[['frameid']] = final_df[['frameid']].astype(int)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "def add_confident_samples(dataset, selected_samples, df): # concat above\n",
    "\n",
    "    bonus_video, bonus_frame = [], []\n",
    "    for id_samples in selected_samples:\n",
    "        # Access samples by id sample\n",
    "        sample = dataset[id_samples]\n",
    "\n",
    "        bonus_video.append(sample['video'])\n",
    "        bonus_frame.append(int(sample['frameid']))\n",
    "\n",
    "    # print(df.dtypes)\n",
    "        \n",
    "    bonus_df = pd.DataFrame({'video': bonus_video, 'frameid': bonus_frame})\n",
    "    \n",
    "    # print(bonus_df.dtypes)\n",
    "    \n",
    "    res_df = combine_df(bonus_df, df)\n",
    "    \n",
    "    # print(res_df.dtypes)\n",
    "    \n",
    "    return res_df\n",
    "\n",
    "\n",
    "def get_neighbor_frames(video, frameid, delta=100):\n",
    "\n",
    "    def search(frameid, frameid_list):\n",
    "        found_index = -1\n",
    "        l, r = 0, len(frameid_list) - 1\n",
    "        while l <= r:\n",
    "            mid = (l + r)//2\n",
    "            if frameid_list[mid] >= frameid:\n",
    "                found_index = mid\n",
    "                r = mid - 1\n",
    "            else:\n",
    "                l = mid + 1\n",
    "\n",
    "        return found_index\n",
    "\n",
    "    def get_neighbor_list(frameid, frameid_list, delta):\n",
    "        index = search(frameid, frameid_list)\n",
    "        left, right = max(\n",
    "            0, index - delta), min(len(frameid_list), index + delta)\n",
    "        neighbor_frameid_list = frameid_list[left:right]\n",
    "        return neighbor_frameid_list\n",
    "\n",
    "    path_frames_video = os.path.join(PATH_KEYFRAMES, video)\n",
    "    frameid_list = sorted(os.listdir(path_frames_video))\n",
    "\n",
    "    neighbor_frameid_list = get_neighbor_list(frameid, frameid_list, delta)\n",
    "    neighbor_frameid_list = [os.path.join(\n",
    "        path_frames_video, file) for file in neighbor_frameid_list]\n",
    "\n",
    "    return neighbor_frameid_list\n",
    "\n",
    "def get_fps(video_name):\n",
    "\n",
    "    path_meta = os.path.join(PATH_METADATA, video_name + '.json')\n",
    "\n",
    "    data = None\n",
    "    with open(path_meta, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    return data['fps']\n",
    "\n",
    "\n",
    "def get_url(video_name):\n",
    "\n",
    "    path_meta = os.path.join(PATH_METADATA, video_name + '.json')\n",
    "\n",
    "    data = None\n",
    "    with open(path_meta, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    return data['watch_url']\n",
    "\n",
    "def get_timestamp(fps, frame_id):\n",
    "    '''\n",
    "    Get the timestamp of a frame\n",
    "    Args:\n",
    "        fps: fps of the video\n",
    "        frame_id: frame id\n",
    "    Returns:\n",
    "        timestamp: tuple of (hour, minute, second)\n",
    "    '''\n",
    "    hour = int(frame_id / (fps * 3600))\n",
    "    minute = int((frame_id - hour * fps * 3600) / (fps * 60))\n",
    "    second = int((frame_id - hour * fps * 3600 - minute * fps * 60) / fps)\n",
    "    return (hour, minute, second)\n",
    "\n",
    "def get_frame_id(video_name, fps, timestamp=(0,0,0), path_frames=PATH_KEYFRAMES):\n",
    "    '''\n",
    "    Get the closest frame id (in folder at path_frames) of a video at a given timestamp\n",
    "    Args:\n",
    "        video_name: name of the video\n",
    "        timestamp: tuple of (hour, minute, second)\n",
    "        path_frames: path to the frames (default to './frames')\n",
    "    Returns:\n",
    "        frame_id: frame id\n",
    "    '''\n",
    "    true_frame_id = timestamp[0] * fps * 3600 + timestamp[1] * fps * 60 + timestamp[2] * fps\n",
    "    # all_frames = [int(frame.split('.')[0]) for frame in os.listdir(os.path.join(path_frames, video_name.split('.')[0]))]\n",
    "    # closest_frame_id = min(all_frames, key=lambda x:abs(x-true_frame_id))\n",
    "    return true_frame_id\n",
    "\n",
    "\n",
    "def submit_result(item, frame, session):\n",
    "    \n",
    "    url = 'https://eventretrieval.one/api/v1/submit'\n",
    "    params = {\n",
    "    'item': item,\n",
    "    'frame': frame,\n",
    "    'session': session\n",
    "    }\n",
    "\n",
    "    r = requests.get(url, params)\n",
    "    res = r.json()\n",
    "    return res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## *1. Load top samples with highest score from inference notebook* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 2\n",
    "\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir='submission/{}_top_k_images'.format(id),\n",
    "    dataset_type=fo.types.FiftyOneDataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## *2. Adjust Submission*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 Launch App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    }
   ],
   "source": [
    "session = fo.launch_app(dataset, auto=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Finalize Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({'video': [], 'frameid': []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Select 100 first samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select\n",
    "head_100_samples_id = [sample['id'] for sample in dataset][:100]\n",
    "session.select_samples(head_100_samples_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected samples id\n",
    "selected_samples = session.selected\n",
    "# Add to submission\n",
    "df_submission = add_confident_samples(dataset, selected_samples, df_submission)\n",
    "# Clear selected samples\n",
    "session.clear_selected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Modify result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose (tick select) samples which are reliable <br />\n",
    "<span style=\"color:red\">**Notice**:</span> *The order of samples add to the submission dataframe is equivalent to the order of the user choose*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.open('http://localhost:5151/');"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select GUI above\n",
    "session.open_tab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected samples id\n",
    "selected_samples = session.selected\n",
    "# Add to submission\n",
    "df_submission = add_confident_samples(dataset, selected_samples, df_submission)\n",
    "# Clear selected samples\n",
    "session.clear_selected()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Optional*: If can not find desireable samples, but we suspect some samples that related to answer. Otherwise, skipping below stuff and moving to **Section 3**\n",
    "- **1st alternative method**: 2.2.2.1 Get neighbor frames around that frames -> append to above submission\n",
    "- **2nd alternative method**: 2.2.2.2 Have a timestamp on video which are matched with query -> append to above submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **2.2.2.1 Select neighbor frames**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input video and frameid of suspected sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = 'C00_V0221'\n",
    "frameid = '005966.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Export neighbor frames of suspected sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████| 200/200 [48.3ms elapsed, 0s remaining, 4.1K samples/s]   \n",
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?context=ipython&subscription=1820ffd4-086f-4568-bb82-0f4e42c2c4b7\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f37755be1c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neighbor_frameid_list = get_neighbor_frames(\n",
    "    video=video, frameid=frameid, delta=100)\n",
    "\n",
    "neighbor_dataset = fo.Dataset.from_images(\n",
    "    neighbor_frameid_list\n",
    ")\n",
    "\n",
    "for sample in neighbor_dataset:\n",
    "    _, sample['video'], sample['frameid'] = sample['filepath'][:-\n",
    "                                                               4].rsplit('/', 2)\n",
    "    sample.save()\n",
    "\n",
    "\n",
    "neighbor_session = fo.launch_app(neighbor_dataset, auto=False)\n",
    "neighbor_session.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize and select neighbor that match with query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select opened GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected samples id\n",
    "selected_samples = neighbor_session.selected\n",
    "# Add to submission\n",
    "df_submission = add_confident_samples(neighbor_dataset, selected_samples, df_submission)\n",
    "# Clear selected samples\n",
    "neighbor_session.clear_selected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **2.2.2.2 Get frames based on timestamp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'C00_V0000.mp4'\n",
    "timestamp  = (0, 12, 30)\n",
    "fps = 25\n",
    "\n",
    "frame_id = get_frame_id(video_name, fps, timestamp)\n",
    "\n",
    "df_bonus_add = pd.DataFrame({'video': [video_name], 'frameid': [frame_id]})\n",
    "\n",
    "df_submission = combine_df(df_bonus_add, df_submission)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validate by viewing video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.17.4 Vetinari (revision 3.0.13-8-g41878ff4f2)\n",
      "[\u001b[32;1m0000561d2ec5bab0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "[\u001b[32;1m00007fdf2c007a00\u001b[0m] gl gl: \u001b[0;1mInitialized libplacebo v4.208.0 (API v208)\u001b[0m\n",
      "[\u001b[32;1m00007fdf2c007a00\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaCreateSurfaces: attribute not supported\u001b[0m\n",
      "[\u001b[32;1m00007fdf280563c0\u001b[0m] main video output error: \u001b[31;1mvideo output creation failed\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mfailed to create video output\u001b[0m\n",
      "[\u001b[32;1m00007fdf2c007a00\u001b[0m] gl gl: \u001b[0;1mInitialized libplacebo v4.208.0 (API v208)\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] avcodec decoder: \u001b[0;1mUsing NVIDIA VDPAU Driver Shared Library  515.76  Mon Sep 12 19:09:07 UTC 2022 for hardware decoding\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mTimestamp conversion failed for 52080001: no reference clock\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mCould not convert timestamp 0 for FFmpeg\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mTimestamp conversion failed for 58560001: no reference clock\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mCould not convert timestamp 0 for FFmpeg\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mTimestamp conversion failed (delay 1000000, buffering 100000, bound 9000000)\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mCould not convert timestamp 8353271697 for FFmpeg\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mTimestamp conversion failed for 59840001: no reference clock\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mCould not convert timestamp 0 for FFmpeg\u001b[0m\n",
      "[\u001b[32;1m00007fdf3ccc1d10\u001b[0m] main decoder error: \u001b[31;1mTimestamp conversion failed for 38150386: no reference clock\u001b[0m\n",
      "[\u001b[32;1m00007fdf3ccc1d10\u001b[0m] main decoder error: \u001b[31;1mCould not convert timestamp 0 for faad\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mTimestamp conversion failed for 31640001: no reference clock\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mCould not convert timestamp 0 for FFmpeg\u001b[0m\n",
      "[\u001b[32;1m00007fdf3ccc1d10\u001b[0m] main decoder error: \u001b[31;1mTimestamp conversion failed for 18343765: no reference clock\u001b[0m\n",
      "[\u001b[32;1m00007fdf3ccc1d10\u001b[0m] main decoder error: \u001b[31;1mCould not convert timestamp 0 for faad\u001b[0m\n",
      "[\u001b[32;1m00007fdf3ccc1d10\u001b[0m] main decoder error: \u001b[31;1mTimestamp conversion failed for 45650431: no reference clock\u001b[0m\n",
      "[\u001b[32;1m00007fdf3ccc1d10\u001b[0m] main decoder error: \u001b[31;1mCould not convert timestamp 0 for faad\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mTimestamp conversion failed for 51080001: no reference clock\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mCould not convert timestamp 0 for FFmpeg\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mTimestamp conversion failed for 58000001: no reference clock\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mCould not convert timestamp 0 for FFmpeg\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mTimestamp conversion failed for 167520001: no reference clock\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mCould not convert timestamp 0 for FFmpeg\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mTimestamp conversion failed for 196920001: no reference clock\u001b[0m\n",
      "[\u001b[32;1m00007fdf3cc12f80\u001b[0m] main decoder error: \u001b[31;1mCould not convert timestamp 0 for FFmpeg\u001b[0m\n",
      "\u001b[31muint DBusMenuExporterDBus::GetLayout(int, int, const QStringList&, DBusMenuLayoutItem&)\u001b[0m: Condition failed: menu\n",
      "\u001b[31muint DBusMenuExporterDBus::GetLayout(int, int, const QStringList&, DBusMenuLayoutItem&)\u001b[0m: Condition failed: menu\n"
     ]
    }
   ],
   "source": [
    "video_name = 'C02_V0381'\n",
    "frame_id = '001280'\n",
    "\n",
    "h,m,s = get_timestamp(get_fps(video_name), int(frame_id))\n",
    "\n",
    "total_second = h * 3600 + m * 60 + s\n",
    "video_path = os.path.join('/run/media/zephy_manjaro/Crucial\\ X6/AIC2022/data/video/', video_name + '.mp4')\n",
    "\n",
    "# Play video\n",
    "!vlc --start-time=$total_second  $video_path \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>frameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C00_V0047</td>\n",
       "      <td>22446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C00_V0041</td>\n",
       "      <td>2753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C00_V0047</td>\n",
       "      <td>21054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C00_V0047</td>\n",
       "      <td>21088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C00_V0047</td>\n",
       "      <td>21280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>C01_V0228</td>\n",
       "      <td>12982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>C01_V0231</td>\n",
       "      <td>9659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>C01_V0232</td>\n",
       "      <td>10323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>C01_V0232</td>\n",
       "      <td>10934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>C01_V0233</td>\n",
       "      <td>12066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video  frameid\n",
       "0   C00_V0047    22446\n",
       "1   C00_V0041     2753\n",
       "2   C00_V0047    21054\n",
       "3   C00_V0047    21088\n",
       "4   C00_V0047    21280\n",
       "..        ...      ...\n",
       "95  C01_V0228    12982\n",
       "96  C01_V0231     9659\n",
       "97  C01_V0232    10323\n",
       "98  C01_V0232    10934\n",
       "99  C01_V0233    12066\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check submission format\n",
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Media item 'C00_V0041 (collection = UID(7e96588b-761d-45db-a86c-c73d8638c0f4))' could not be found.\",\n",
       " 'status': False}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = df_submission['video'][0]\n",
    "frame = df_submission['frameid'][0]\n",
    "session = 'node0lr605kqgqel0ztycevox5s5k21'\n",
    "\n",
    "submit_result(item, frame, session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a01b3139ca24efc76fe93ca0f6fd5631c22ec2f7f45d68398316348b341d0835"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
